#!/usr/bin/env python2
'''

    if processed: continue
    if on_s3 or force: continue
    upload()

    YYYYMMDD.tgz -> YYYYMMDD.tgz.gpg
    s3://capture/YYYYMMDD

'''
import json
import os
import sys
from os.path import join
from glob import glob
from datetime import *
import shutil

import boto

ROOT = os.path.dirname(os.path.realpath(__file__))
ROOT = join(ROOT, '..')
FRAMES = join(ROOT, 'frames')
os.chdir(FRAMES)

class Indexer:

    def __init__(self, settings):
        self.settings = settings
        access = str(self.settings['access-key'])
        secret = str(self.settings['secret-key'])
        self.s3 = boto.connect_s3(access, secret, is_secure=True)
        self.bucket = self.s3.get_bucket(settings['bucket'])
        self.sdb = boto.connect_sdb(access, secret)
        self.sdb_day = self.get_domain('day')
        self.sdb_image = self.get_domain('image')

    def get_domain(self, d):
        prefix = str(self.settings['domain-prefix'])
        domain = self.sdb.get_domain(prefix + d)
        assert(domain)
        return domain

    @staticmethod
    def ts2dt(ts):
        ts = os.path.split(ts)[1]
        ts = os.path.splitext(ts)[0]
        ts = float(ts)
        return ts

    @staticmethod
    def d2dt(d):
        return datetime.strptime(d, '%Y%m%d').date()

    def get_item(self, domain, key):
        item = domain.get_item(key)
        if not item:
            item = domain.new_item(key)
        return item

    def update_image(self, day, f):
        ts = Indexer.ts2dt(f)
        print ts
        image_item = self.get_item(self.sdb_image, ts)
        image_item['day'] = day.isoformat()
        image_item['path'] = f
        image_item.save()
        return image_item

    def exe(self, cmd):
        print cmd
        ret = os.system(cmd)
        if ret:
            print 'cmd:', cmd
            print 'failed with exit code:', ret
            sys.exit(1)

    def loop(self):
        bucket = self.bucket
        directories = glob('*')
        if os.path.exists('tmp'):
            shutil.rmtree('tmp')
            os.mkdir('tmp')
        for d in directories:

            if d.endswith('_ip'):
                continue
            if d == 'tmp':
                continue

            day = Indexer.d2dt(d)
            if day.today() == day:
                print 'skipping today!'
                continue

            day_item = self.get_item(self.sdb_day, day.isoformat())

            if day_item.get('uploaded'):
                print day, 'already uploaded (db), deleting and skipping...'
                shutil.rmtree(d)
                shutil.rmtree(d + '_ip')
                continue

            if not self.settings.get('overwrite-s3') and bucket.lookup(d):
                print day, 'already uploaded (s3), skipping...'
                day_item['uploaded'] = True
                day_item.save()
                continue

            files = glob(join(d, '*jpg'))
            #for f in files:
            #    self.update_image(day, unicode(f))

            self.exe('tar czf tmp/%s.tgz %s %s_ip' % (d, d, d))
            self.exe('echo %s|gpg --batch --yes --passphrase-fd 0 '
                '-c tmp/%s.tgz' % (self.settings['gpg-password'], d))

            print day, 'uploading...'
            key = bucket.new_key(d)
            key.set_contents_from_filename('tmp/%s.tgz.gpg' % d)
            day_item['uploaded'] = True
            day_item.save()

            self.exe('rm tmp/*.tgz')

def main():
    settings = json.load(open(join(ROOT, 'settings.json')))
    Indexer(settings).loop()

if __name__ == '__main__':
    main()

